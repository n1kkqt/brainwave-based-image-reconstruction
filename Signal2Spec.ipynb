{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T6cpDCDK9KP",
        "outputId": "3bf8dcdf-dd7a-42ff-d999-ec2c824e5c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/out_files.zip\n",
        "#!unzip /content/drive/MyDrive/MindBigData-Imagenet-IN.zip"
      ],
      "metadata": {
        "id": "oJ1pU6RwQb9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlDT8zmhJg7C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import spectrogram\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2\n",
        "\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Conv Blocks\n",
        "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, \n",
        "    padding=padding)\n",
        "\n",
        "\n",
        "def conv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, inst_norm=False):\n",
        "    if inst_norm == True:\n",
        "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, \n",
        "        stride=stride, padding=padding), nn.InstanceNorm2d(out_channels, \n",
        "        momentum=0.1, eps=1e-5),)\n",
        "    else:\n",
        "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, \n",
        "        stride=stride, padding=padding), nn.BatchNorm2d(out_channels, \n",
        "        momentum=0.1, eps=1e-5),)\n",
        "\n",
        "def tconv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0,):\n",
        "    return nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, \n",
        "    padding=padding, output_padding=output_padding)\n",
        "    \n",
        "def tconv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, inst_norm=False):\n",
        "    if inst_norm == True:\n",
        "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, \n",
        "        stride=stride, padding=padding, output_padding=output_padding), \n",
        "        nn.InstanceNorm2d(out_channels, momentum=0.1, eps=1e-5),)\n",
        "    else:\n",
        "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, \n",
        "        stride=stride, padding=padding, output_padding=output_padding), \n",
        "        nn.BatchNorm2d(out_channels, momentum=0.1, eps=1e-5),)"
      ],
      "metadata": {
        "id": "Li7G_U6RD_Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generator\n",
        "class Gen(nn.Module):\n",
        "    def __init__(self, dim_c=5, dim_g=32, inst_norm=False):\n",
        "        super(Gen, self).__init__()\n",
        "        self.n1 = conv(dim_c, dim_g, 4, 2, 1) \n",
        "        self.n2 = conv_n(dim_g, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.n3 = conv_n(dim_g*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.n4 = conv_n(dim_g*4, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.n5 = conv_n(dim_g*4, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
        "        #self.n6 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
        "        #self.n7 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
        "        #self.n8 = conv(dim_g*8, dim_g*8, 4, 2, 1)\n",
        "        self.m1 = tconv_n(dim_g*4, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.m2 = tconv_n(dim_g*4*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.m3 = tconv_n(dim_g*4*2, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.m4 = tconv_n(dim_g*4, dim_g, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.m5 = tconv(dim_g*1*2, 3, 4, 2, 1)\n",
        "        #self.m6 = tconv_n(dim_g*4*2, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
        "        #self.m7 = tconv_n(dim_g*2*2, dim_g*1, 4, 2, 1, inst_norm=inst_norm)\n",
        "        #self.m8 = tconv(dim_g*1*2, dim_c, 4, 2, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        n1 = self.n1(x)\n",
        "        n2 = self.n2(F.leaky_relu(n1, 0.2))\n",
        "        n3 = self.n3(F.leaky_relu(n2, 0.2))\n",
        "        n4 = self.n4(F.leaky_relu(n3, 0.2))\n",
        "        n5 = self.n5(F.leaky_relu(n4, 0.2))\n",
        "        m1 = torch.cat([F.dropout(self.m1(F.relu(n5)), 0.5, training=True), n4], 1)\n",
        "        m2 = torch.cat([F.dropout(self.m2(F.relu(m1)), 0.5, training=True), n3], 1)\n",
        "        m3 = torch.cat([F.dropout(self.m3(F.relu(m2)), 0.5, training=True), n2], 1)\n",
        "        m4 = torch.cat([self.m4(F.relu(m3)), n1], 1)\n",
        "        m5 = self.m5(F.relu(m4))\n",
        "        return self.tanh(m5)"
      ],
      "metadata": {
        "id": "5UgaqYbuD2ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Discriminator\n",
        "\n",
        "class Disc(nn.Module):\n",
        "    def __init__(self, dim_cx=5, dim_cy=3, dim_d=32, inst_norm=False): \n",
        "        super(Disc, self).__init__()\n",
        "        self.c1 = conv(dim_cx+dim_cy, dim_d, 4, 2, 1) \n",
        "        self.c2 = conv_n(dim_d, dim_d*2, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.c3 = conv_n(dim_d*2, dim_d*4, 4, 2, 1, inst_norm=inst_norm)\n",
        "        self.c4 = conv_n(dim_d*4, dim_d*8, 4, 1, 1, inst_norm=inst_norm)\n",
        "        self.c5 = conv(dim_d*8, 1, 4, 1, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x, y):\n",
        "        xy=torch.cat([x,y],dim=1)\n",
        "        xy=F.leaky_relu(self.c1(xy), 0.2)\n",
        "        xy=F.leaky_relu(self.c2(xy), 0.2)\n",
        "        xy=F.leaky_relu(self.c3(xy), 0.2)\n",
        "        xy=F.leaky_relu(self.c4(xy), 0.2)\n",
        "        xy=self.c5(xy)\n",
        "        return self.sigmoid(xy)\n",
        "\n",
        "def weights_init(z):\n",
        "    cls_name =z.__class__.__name__\n",
        "    if cls_name.find('Conv')!=-1 or cls_name.find('Linear')!=-1: \n",
        "        nn.init.normal_(z.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(z.bias.data, 0)\n",
        "    elif cls_name.find('BatchNorm')!=-1:\n",
        "        nn.init.normal_(z.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(z.bias.data, 0)"
      ],
      "metadata": {
        "id": "uMXILf40cZpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_spec(Xdb, p, hop_length=6, win_length=32):\n",
        "  Sinv = librosa.db_to_amplitude(Xdb)\n",
        "  ts = librosa.istft(Sinv * p, hop_length=hop_length, win_length=win_length)\n",
        "  return ts\n",
        "\n",
        "def to_spec(ts, n_fft=128, hop_length=6, win_length=32):\n",
        "  X = librosa.stft(ts, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
        "  Smag, p = librosa.magphase(X)\n",
        "  Xdb = librosa.amplitude_to_db(Smag, top_db=None)\n",
        "  Xdb = cv2.resize(Xdb, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
        "  return Xdb, p\n",
        "\n",
        "def scale_minmax(X, min=0.0, max=1.0):\n",
        "    X_std = (X - X.min()) / (X.max() - X.min())\n",
        "    X_scaled = X_std * (max - min) + min\n",
        "    return X_scaled"
      ],
      "metadata": {
        "id": "5UZFNcjA1g8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_spec_matrix = lambda brain_ts: np.concatenate([np.expand_dims(scale_minmax(to_spec(brain_ts[:,i], n_fft=128, hop_length=6, win_length=64)[0], min=-1.0, max=1.0), 0) for i in range(brain_ts.shape[1])], 0)\n",
        "\n",
        "def csv_to_spec_matrix(csv):\n",
        "  brain_ts = pd.read_csv(csv, index_col=0, header=None).T[-360:]\n",
        "  brain_ts = (brain_ts - brain_ts.mean()) / brain_ts.std()\n",
        "  brain_ts = brain_ts.reset_index(drop=True).to_numpy()\n",
        "  spec_matrix = convert_to_spec_matrix(brain_ts)\n",
        "  return spec_matrix"
      ],
      "metadata": {
        "id": "Yvcx_pnt3-Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_imgs = lambda xy: [Image.fromarray((((el * 0.5) + 0.5) * 255).to(torch.uint8).permute(1, 2, 0).detach().cpu().numpy()).resize((256,256)) for el in xy]"
      ],
      "metadata": {
        "id": "l_LAzhlaTAXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TSDataset(Dataset):\n",
        "    def __init__(self, data_split_path):\n",
        "        self.input_data, self.output_data = torch.load(data_split_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_data[idx], self.output_data[idx]"
      ],
      "metadata": {
        "id": "AOq5WT1BuvQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_imgs_csvs_labels_path = '/content/drive/MyDrive/TSS Tensors/new_imgs_csvs_labels.pt'\n",
        "ts_images_path = '/content/drive/MyDrive/TSS Tensors/ts_images.pt'\n",
        "img_array_path = '/content/drive/MyDrive/TSS Tensors/images.pt'\n",
        "train_path = '/content/drive/MyDrive/TSS Tensors/train.pt'\n",
        "test_path = '/content/drive/MyDrive/TSS Tensors/test.pt'\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((64,64)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),])\n",
        "\n",
        "new_imgs, csvs, labels = torch.load(new_imgs_csvs_labels_path)\n",
        "\n",
        "'''\n",
        "if os.path.exists(ts_images_path):\n",
        "  input_data = torch.load(ts_images_path)\n",
        "else:\n",
        "  input_data = [torch.Tensor(csv_to_spec_matrix(csv)) for csv in tqdm(csvs)]\n",
        "  torch.save(input_data, ts_images_path)\n",
        "\n",
        "if os.path.exists(img_array_path):\n",
        "  output_data = torch.load(img_array_path)\n",
        "else:\n",
        "  output_data = [transform(Image.open(img).convert('RGB')) for img in tqdm(new_imgs)]\n",
        "  torch.save(output_data, img_array_path)\n",
        "\n",
        "input_train, input_test, output_train, output_test = train_test_split(input_data, output_data, test_size=0.15, random_state=42)\n",
        "torch.save((input_train, output_train), train_path)\n",
        "torch.save((input_test, output_test), test_path)\n",
        "''';"
      ],
      "metadata": {
        "id": "NMbz0pYnLBb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 16\n",
        "inst_norm = True if bs==1 else False  # instance normalization\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = Gen().to(device)\n",
        "discriminator = Disc().to(device)\n",
        "train_ds = TSDataset(train_path)\n",
        "test_ds = TSDataset(test_path)\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=bs, shuffle=False)"
      ],
      "metadata": {
        "id": "ZTBUQCnLbtIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BCE = nn.BCELoss()\n",
        "L1 = nn.L1Loss() \n",
        "\n",
        "Gen_optim = optim.AdamW(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "Disc_optim = optim.AdamW(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "fe4YVt310pA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = []\n",
        "Disc_losses = Gen_losses = Gen_GAN_losses = Gen_L1_losses = []\n",
        "iter_per_plot = 100\n",
        "epochs = 50\n",
        "L1_lambda = 100.0\n",
        "\n",
        "for ep in range(epochs):\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        size = data[0].shape[0]\n",
        "        x, y = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        r_masks = torch.ones(size,1,6,6).to(device)\n",
        "        f_masks = torch.zeros(size,1,6,6).to(device)\n",
        "        # disc\n",
        "        discriminator.zero_grad()\n",
        "        #real_patch\n",
        "        r_patch = discriminator(x, y)\n",
        "        r_gan_loss = BCE(r_patch, r_masks)\n",
        "        fake = generator(x)\n",
        "        #fake_patch\n",
        "        f_patch = discriminator(x, fake.detach())\n",
        "        f_gan_loss = BCE(f_patch, f_masks)\n",
        "        Disc_loss = r_gan_loss + f_gan_loss\n",
        "        Disc_loss.backward()\n",
        "        Disc_optim.step()\n",
        "        # gen\n",
        "        generator.zero_grad()\n",
        "        f_patch = discriminator(x, fake)\n",
        "        f_gan_loss = BCE(f_patch, r_masks)\n",
        "        L1_loss = L1(fake, y)\n",
        "        Gen_loss = f_gan_loss + L1_lambda * L1_loss\n",
        "        Gen_loss.backward()\n",
        "    \n",
        "        Gen_optim.step()\n",
        "\n",
        "        if (i+1)%iter_per_plot == 0:\n",
        "          print('Epoch [{}/{}], Step [{}/{}], disc_loss: {:.4f}, gen_loss: {:.4f},Disc(real): {:.2f}, Disc(fake):{:.2f}, gen_loss_gan:{:.4f}, gen_loss_L1:{:.4f}'.format(ep, epochs, i+1, len(train_dataloader), Disc_loss.item(), Gen_loss.item(), r_patch.mean(), f_patch.mean(), f_gan_loss.item(), L1_loss.item()))\n",
        "        \n",
        "    for data in test_dataloader:\n",
        "      x, y = data\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      with torch.no_grad():\n",
        "        generator.eval()\n",
        "        fake = generator(x)\n",
        "        generator.train()\n",
        "      break\n",
        "\n",
        "    faket, yt = to_imgs(fake), to_imgs(y)\n",
        "\n",
        "    for fi, yi in zip(faket, yt):\n",
        "      display(fi)\n",
        "      display(yi)\n",
        "      print('-'*20)"
      ],
      "metadata": {
        "id": "YFRuCHNCzy4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(test_dataloader):\n",
        "  x, y = data\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  with torch.no_grad():\n",
        "    generator.eval()\n",
        "    fake = generator(x)\n",
        "    generator.train()\n",
        "  \n",
        "  if i > 2:\n",
        "    break\n",
        "\n",
        "faket, yt = to_imgs(fake), to_imgs(y)\n",
        "\n",
        "for fi, yi in zip(faket, yt):\n",
        "  display(fi)\n",
        "  display(yi)\n",
        "  print('-'*20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "B6vnDTb4lDcd",
        "outputId": "a2c3b04d-793a-43f6-ec83-f9f0974de725"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fdc073f6c853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ts = brain_ts[:,2]\n",
        "#Xdb, p = to_spec(ts, n_fft=128, hop_length=6, win_length=64)\n",
        "#print(Xdb.shape)\n",
        "#Image.fromarray(scale_minmax(Xdb, min=0.0, max=255.0).astype(np.uint8))\n",
        "#plt.figure(figsize=(14, 5))\n",
        "#librosa.display.specshow(Xdb, sr=128, x_axis='time', y_axis='hz')\n",
        "#plt.colorbar()"
      ],
      "metadata": {
        "id": "p9cGZAIx1BVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3VFdrAcBf6QE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}